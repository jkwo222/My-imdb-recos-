# .github/workflows/nightly.yml
name: nightly

on:
  workflow_dispatch:
  schedule:
    - cron: "0 13 * * *"   # optional daily run at 13:00 UTC

jobs:
  build:
    runs-on: ubuntu-latest

    env:
      TMDB_ACCESS_TOKEN: ${{ secrets.TMDB_ACCESS_TOKEN }}
      IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
      REGION: US
      ORIGINAL_LANGS: en
      SUBS_INCLUDE: netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus
      DISCOVER_PAGES: 3
      ROTATE_MINUTES: 60
      PAGE_CAP: 1000
      STEP: 37

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install rapidfuzz "pandas<3" requests

      - name: Prepare output dirs
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          RUN_DIR="data/out/run_${{ github.run_id }}_${{ github.run_number }}"
          LATEST_DIR="data/out/latest"
          ART_DIR="artifacts"
          mkdir -p "$RUN_DIR" "$LATEST_DIR" "$ART_DIR" data data/cache/tmdb
          echo "run_dir=$RUN_DIR"   >> "$GITHUB_OUTPUT"
          echo "latest_dir=$LATEST_DIR" >> "$GITHUB_OUTPUT"
          echo "art_dir=$ART_DIR"   >> "$GITHUB_OUTPUT"

      - name: Quick self-check (optional)
        continue-on-error: true
        run: |
          python - <<'PY'
          try:
              from engine.self_check import run_self_check
              run_self_check()
              print("SELF-CHECK: OK")
          except Exception as e:
              print("SELF-CHECK: SKIPPED/FAILED:", e)
          PY

      - name: Run catalog
        env:
          REGION: ${{ env.REGION }}
          ORIGINAL_LANGS: ${{ env.ORIGINAL_LANGS }}
          SUBS_INCLUDE: ${{ env.SUBS_INCLUDE }}
          DISCOVER_PAGES: ${{ env.DISCOVER_PAGES }}
          ROTATE_MINUTES: ${{ env.ROTATE_MINUTES }}
          PAGE_CAP: ${{ env.PAGE_CAP }}
          STEP: ${{ env.STEP }}
          TMDB_ACCESS_TOKEN: ${{ env.TMDB_ACCESS_TOKEN }}
          IMDB_USER_ID: ${{ env.IMDB_USER_ID }}
        run: |
          set -euo pipefail
          RUN_DIR="${{ steps.prep.outputs.run_dir }}"
          LATEST_DIR="${{ steps.prep.outputs.latest_dir }}"
          python -m engine.runner 2>&1 | tee "$RUN_DIR/runner.log" || true

          for cand in \
            "assistant_feed.json" \
            "data/assistant_feed.json" \
            "data/out/assistant_feed.json" \
            "$RUN_DIR/assistant_feed.json" \
            "out/assistant_feed.json"
          do
            if [ -f "$cand" ]; then
              cp -f "$cand" "$RUN_DIR/assistant_feed.json"
              break
            fi
          done
          if [ ! -f "$RUN_DIR/assistant_feed.json" ]; then
            echo "[]" > "$RUN_DIR/assistant_feed.json"
          fi
          if grep -q "Daily recommendations" "$RUN_DIR/runner.log" 2>/dev/null; then
            awk 'BEGIN{p=0}/^# Daily recommendations/{p=1}p' "$RUN_DIR/runner.log" > "$RUN_DIR/summary.md" || true
          fi
          if [ ! -s "$RUN_DIR/summary.md" ]; then
            echo "# Daily recommendations" > "$RUN_DIR/summary.md"
            echo "" >> "$RUN_DIR/summary.md"
            echo "_No summary captured; see runner.log for details._" >> "$RUN_DIR/summary.md"
          fi
          rsync -a --delete "$RUN_DIR/" "$LATEST_DIR/"

      - name: Build debug-data zip
        shell: bash
        run: |
          set -euo pipefail
          ART_DIR="${{ steps.prep.outputs.art_dir }}"
          RUN_DIR="${{ steps.prep.outputs.run_dir }}"
          DEBUG_ZIP="$ART_DIR/debug-data_${{ github.run_id }}.zip"
          mkdir -p "$ART_DIR"
          ZIP_LIST=()
          [ -f "$RUN_DIR/runner.log" ] && ZIP_LIST+=("$RUN_DIR/runner.log")
          [ -f "$RUN_DIR/assistant_feed.json" ] && ZIP_LIST+=("$RUN_DIR/assistant_feed.json")
          [ -f "$RUN_DIR/summary.md" ] && ZIP_LIST+=("$RUN_DIR/summary.md")
          [ -f "data/ratings.csv" ] && ZIP_LIST+=("data/ratings.csv")
          [ -d "data/cache/tmdb" ] && ZIP_LIST+=("data/cache/tmdb")
          [ -f ".env" ] && ZIP_LIST+=(".env")
          if [ "${#ZIP_LIST[@]}" -eq 0 ]; then
            echo "no-debug-files" > "$ART_DIR/README.txt"
            ZIP_LIST+=("$ART_DIR/README.txt")
          fi
          zip -9 -r "$DEBUG_ZIP" "${ZIP_LIST[@]}" \
            -x "*.pyc" "*.pyo" "__pycache__/*" ".git/*" || true
          echo "debug_zip=$DEBUG_ZIP" >> "$GITHUB_OUTPUT"

      - name: Upload latest-out
        uses: actions/upload-artifact@v4
        with:
          name: latest-out
          path: data/out/latest/**
          if-no-files-found: warn
          retention-days: 14

      - name: Upload debug-data
        uses: actions/upload-artifact@v4
        with:
          name: debug-data
          path: artifacts/debug-data_*.zip
          if-no-files-found: warn
          retention-days: 14

      - name: Upload raw run folder (optional)
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: raw-run
          path: ${{ steps.prep.outputs.run_dir }}/**
          if-no-files-found: warn
          retention-days: 7

      - name: Cleanup old runs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/out
          cd data/out
          ls -1d run_* 2>/dev/null | sort -r | awk 'NR>7' | xargs -r rm -rf