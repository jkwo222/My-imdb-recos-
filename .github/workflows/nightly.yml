name: nightly

on:
  schedule:
    - cron: "0 3 * * *"   # 3:00 UTC daily
  workflow_dispatch: {}

permissions:
  contents: write
  issues: write

jobs:
  build:
    runs-on: ubuntu-24.04
    env:
      TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
      TMDB_ACCESS_TOKEN: ${{ secrets.TMDB_ACCESS_TOKEN }} # â† Read Access Token (v4)
      IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
      REGION: US
      ORIGINAL_LANGS: en
      SUBS_INCLUDE: netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus
      MIN_MATCH_CUT: 58
      DISCOVER_PAGES: 3

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # --- NEW: grab IMDb TSVs nightly so we can cross-check and enrich ---
      - name: Fetch IMDb TSV datasets
        run: |
          set -euxo pipefail
          mkdir -p data/cache/imdb
          pushd data/cache/imdb
          wget -q https://datasets.imdbws.com/title.basics.tsv.gz -O title.basics.tsv.gz
          wget -q https://datasets.imdbws.com/title.ratings.tsv.gz -O title.ratings.tsv.gz
          wget -q https://datasets.imdbws.com/title.akas.tsv.gz -O title.akas.tsv.gz
          gunzip -f title.basics.tsv.gz || true
          gunzip -f title.ratings.tsv.gz || true
          gunzip -f title.akas.tsv.gz || true
          popd

      - name: Run engine
        run: |
          set -e
          python -m engine.runner

      - name: Make debug bundle
        if: always()
        run: |
          set -e
          python -m engine.debug_pack
          ls -lh data/out/latest || true

      # Upload outputs + caches/state for diagnosis
      - name: Upload artifacts (outputs + debug/state + ratings.csv)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: out
          if-no-files-found: warn
          compression-level: 6
          path: |
            data/out/latest
            data/cache/state/personal_state.json
            data/cache/state/personal_history.json
            data/cache/state/persistent_pool.json
            data/cache/feedback
            data/cache/tmdb
            data/cache/imdb
            data/user/ratings.csv

      - name: Add summary to run
        if: always()
        run: |
          echo "## Daily recommendations" >> "$GITHUB_STEP_SUMMARY"
          if [ -f data/out/latest/summary.md ]; then
            cat data/out/latest/summary.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "_No summary produced (data/out/latest/summary.md missing)._ " >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Ensure gh CLI
        if: always()
        run: |
          if ! command -v gh >/dev/null 2>&1; then
            echo "gh CLI missing."; exit 0
          fi

      - name: Create/find 'Daily Recommendations' issue and comment results
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          TITLE="Daily Recommendations"
          BODY="No summary produced for this run."
          if [ -f data/out/latest/summary.md ]; then
            BODY="$(cat data/out/latest/summary.md)"
          fi

          ISSUE_NUMBER=$(gh api -X GET repos/${{ github.repository }}/issues --paginate -q \
            '.[] | select(.state=="open" and .title=="'"$TITLE"'") | .number' | head -n1)

          if [ -z "$ISSUE_NUMBER" ]; then
            ISSUE_NUMBER=$(gh api -X POST repos/${{ github.repository }}/issues \
              -f title="$TITLE" -f body="Tracking thread for daily recommendation digests." -q '.number')
          fi

          gh api -X POST repos/${{ github.repository }}/issues/$ISSUE_NUMBER/comments \
            -f body="$BODY" >/dev/null

          echo "Commented to issue #$ISSUE_NUMBER"