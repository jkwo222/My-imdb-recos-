name: nightly

on:
  # keep your nightly schedule here (adjust cron as you like)
  schedule:
    - cron: "0 5 * * *"   # 05:00 UTC daily
  push:
    branches: [ main ]
  workflow_dispatch: {}

permissions:
  contents: read
  actions: read
  issues: write   # needed so github-script can create/find the issue and comment

jobs:
  build:
    runs-on: ubuntu-24.04

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Prepare dirs + bootstrap log
        run: |
          set -euo pipefail
          mkdir -p data/cache data/debug data/out/latest
          echo "[bootstrap] $(date -u +"%F %T UTC") — workflow started" > data/debug/runner.log

      - name: Recover previous nightly-output artifact (if any)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          ART_ID=$(gh api repos/${{ github.repository }}/actions/artifacts --jq '.artifacts[] | select(.name=="nightly-output") | .id' | head -n1 || true)
          if [[ -n "${ART_ID:-}" ]]; then
            echo "Downloading artifact id ${ART_ID}…"
            gh api -H "Accept: application/vnd.github+json" -X GET repos/${{ github.repository }}/actions/artifacts/${ART_ID}/zip > nightly-output.zip || true
            unzip -qo nightly-output.zip -d . || true
          else
            echo "No previous nightly-output artifact found; starting fresh store."
          fi

      - name: Run engine (capture logs but don’t fail yet)
        id: engine
        env:
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
          OMDB_API_KEY: ${{ secrets.OMDB_API_KEY }}
          IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
          IMDB_RATINGS_CSV_PATH: data/ratings.csv
          REGION: US
          ORIGINAL_LANGS: en
          SUBS_INCLUDE: netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus
          TMDB_PAGES_MOVIE: 24
          TMDB_PAGES_TV: 24
          MAX_CATALOG: 10000
          INCLUDE_TV_SEASONS: true
          SKIP_WINDOW_DAYS: 4
        run: |
          set -euo pipefail
          # run but don’t fail this step yet; we want artifacts uploaded regardless
          set +e
          python -X dev -m engine.runner 2>&1 | tee -a data/debug/runner.log
          EXIT=$?
          set -e
          echo "exit_code=$EXIT" >> "$GITHUB_OUTPUT"
          {
            echo "----- DIR LAYOUT (data/* up to depth 3) -----"
            find data -maxdepth 3 -type f -printf "%p (%s bytes)\n" | sort
          } >> data/debug/runner.log || true

      - name: Build run summary markdown
        run: |
          set -euo pipefail
          FEED="data/out/latest/assistant_feed.json"
          RUN_URL="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          DATE_UTC="$(date -u +'%Y-%m-%d %H:%M UTC')"

          {
            echo "# Nightly Recommendations — ${DATE_UTC}"
            if [ -f "$FEED" ]; then
              POOL=$(jq -r '.telemetry.counts.tmdb_pool // 0' "$FEED")
              UNSEEN=$(jq -r '.telemetry.counts.eligible_unseen // 0' "$FEED")
              SHORT=$(jq -r '.telemetry.counts.shortlist // 0' "$FEED")
              SHOWN=$(jq -r '.telemetry.counts.shown // 0' "$FEED")
              echo
              echo "**Pool:** ${POOL}  •  **Unseen:** ${UNSEEN}  •  **Shortlist:** ${SHORT}  •  **Shown:** ${SHOWN}"
              echo
              echo "## Top 10"
              echo
              echo "| # | Title | Year | Type | Match |"
              echo "|---:|---|---:|---|---:|"
              jq -r '.top10[] | "| \(.rank) | \(.title|gsub("\\|";"\\|")) | \(.year//"") | \(.type) | \(.match) |"' "$FEED"
              echo
            else
              echo
              echo "> No assistant_feed.json produced this run. See logs: ${RUN_URL}"
              echo
            fi
            echo "_Run logs & artifacts:_ ${RUN_URL}"
          } > summary.md

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: nightly-output
          path: |
            data/**
            summary.md
          if-no-files-found: warn
          overwrite: false

      - name: Post summary as issue comment
        uses: actions/github-script@v7
        continue-on-error: true    # don’t fail the job if the API is blocked
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const title = 'Nightly Recommendations';
            const body = fs.readFileSync('summary.md', 'utf8');
            const {owner, repo} = context.repo;
            try {
              const issues = await github.rest.issues.listForRepo({ owner, repo, state: 'open', per_page: 100 });
              let issue = issues.data.find(i => i.title === title);
              if (!issue) {
                const created = await github.rest.issues.create({ owner, repo, title, body: 'This issue will collect nightly recommendation summaries.' });
                issue = created.data;
              }
              await github.rest.issues.createComment({ owner, repo, issue_number: issue.number, body });
              core.info('Posted nightly summary comment.');
            } catch (err) {
              core.warning(`Could not post summary comment: ${err?.message || err}`);
            }

      - name: Fail job if engine failed
        if: steps.engine.outputs.exit_code != '0'
        run: |
          echo "Engine exited with code ${{ steps.engine.outputs.exit_code }}"
          exit ${{ steps.engine.outputs.exit_code }}