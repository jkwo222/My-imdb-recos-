name: nightly

on:
  schedule:
    - cron: '30 7 * * *'   # 07:30 UTC (3:30am ET)
  workflow_dispatch:

permissions:
  contents: read
  issues: write

jobs:
  build:
    runs-on: ubuntu-24.04
    env:
      # Region / discovery
      REGION: US
      ORIGINAL_LANGS: '["en"]'
      SUBS_INCLUDE: apple_tv_plus,netflix,max,paramount_plus,disney_plus,peacock,hulu
      DISCOVER_PAGES: "12"
      DISCOVER_PAGING_MODE: random
      DISCOVER_PAGE_MAX: "200"

      # TMDB auth (either works)
      TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
      TMDB_BEARER:  ${{ secrets.TMDB_ACCESS_TOKEN }}

      # IMDb (optional)
      IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
      IMDB_PUBLIC_MAX_PAGES: "10"

      # Enrichment knobs
      ENRICH_PROVIDERS_TOP_N: "220"
      ENRICH_SCORING_TOP_N: "220"

      # search_multi() fallback tuning (optional)
      SEARCH_MULTI_ON_EMPTY_DETAILS: "true"
      SEARCH_MULTI_ON_MISSING_ID: "true"
      SEARCH_MULTI_TITLE_SIM_TH: "0.62"
      SEARCH_MULTI_YEAR_WEIGHT: "0.35"
      SEARCH_MULTI_TYPE_BONUS: "0.25"

      # Profile model knobs
      AFFINITY_K: "5"
      DECAY_HALF_LIFE_DAYS: "270"

      # Scoring blend knobs
      AUDIENCE_PRIOR_LAMBDA: "0.3"
      PROVIDER_PREF_LAMBDA: "0.5"

      # Anime / Kids penalties
      PENALIZE_KIDS: "true"
      PENALIZE_ANIME: "true"
      KIDS_CARTOON_PENALTY: "25"
      ANIME_PENALTY: "20"

      # Email layout knobs (single digest; no per-title comments)
      EMAIL_TOP_MOVIES: "10"
      EMAIL_TOP_TV: "10"
      EMAIL_SCORE_MIN: "30"
      EMAIL_BACKFILL: "true"
      EMAIL_BACKFILL_MIN: "20"
      EMAIL_BACKFILL_MOVIE_MIN: "20"
      EMAIL_BACKFILL_TV_MIN: "20"
      EMAIL_BACKFILL_ALLOW_ROTATE: "true"
      EMAIL_BACKFILL_FETCH_PROVIDERS: "true"
      EMAIL_EARLY_FETCH_PROVIDERS: "true"
      EMAIL_INCLUDE_TELEMETRY: "true"
      EMAIL_INCLUDE_NEW_MOVIE_LABEL: "true"
      EMAIL_INCLUDE_NEW_SERIES_LABEL: "true"
      EMAIL_INCLUDE_NEW_SEASON_LABEL: "true"
      EMAIL_NETWORK_FALLBACK: "true"

      # Rotation cooldown
      ROTATION_ENABLE: "true"
      ROTATION_COOLDOWN_DAYS: "5"

      # Recency labeling (optional)
      RECENT_MOVIE_MONTHS: "9"
      RECENT_SERIES_DAYS: "120"
      RECENT_SEASON_DAYS: "120"

      # Optional @mention for notifications on the single digest
      NOTIFY_USER: ${{ vars.NOTIFY_USER }}

      # Cache version for pool (bump to invalidate)
      POOL_CACHE_VERSION: v1
      POOL_MAX_ITEMS: "20000"

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      # Restore persistent caches so the pool truly grows
      - name: Restore pool/tmdb caches
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            data/cache/pool
            data/cache/tmdb
          key: pool-${{ runner.os }}-${{ env.REGION }}-${{ env.POOL_CACHE_VERSION }}-${{ github.run_id }}
          restore-keys: |
            pool-${{ runner.os }}-${{ env.REGION }}-${{ env.POOL_CACHE_VERSION }}-

      - name: Run engine (capture log safely)
        shell: bash
        run: |
          set -o pipefail
          mkdir -p data/out data/cache data/out/latest
          python -m engine.runner | tee data/out/latest/runner.log

      # Build single digest using summarize module
      - name: Build digest summary (Top Movies & Top Shows)
        run: |
          python - <<'PY'
          import os
          from pathlib import Path
          from engine.summarize import write_email_markdown
          run_dir = Path("data/out/latest")
          env = {
            "REGION": os.getenv("REGION","US"),
            "SUBS_INCLUDE": [s.strip() for s in (os.getenv("SUBS_INCLUDE","").split(",") if os.getenv("SUBS_INCLUDE") else [])],
          }
          out = write_email_markdown(
            run_dir=run_dir,
            ranked_items_path=run_dir / "items.enriched.json",
            env=env,
          )
          print("summary:", out, "exists:", out.exists())
          PY

      - name: Make debug bundle
        run: |
          chmod +x ./.github/scripts/make_debug_bundle.sh || true
          bash ./.github/scripts/make_debug_bundle.sh

      # Create a clean repo snapshot artifact so uploads never fail
      - name: Create repo snapshot (tracked files at HEAD)
        run: |
          set -e
          rm -f repo-snapshot.zip
          git archive -o repo-snapshot.zip HEAD
          ls -lh repo-snapshot.zip

      # Post/update one Issue with the full digest body only (no per-title comments)
      - name: Post/update Daily Recommendations issue (single digest)
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const title = 'Daily Recommendations';
            const wantLabel = 'daily-recos';

            // 1) Load the summary body
            let body = '';
            try { body = fs.readFileSync('data/out/latest/summary.md', 'utf8'); }
            catch { body = 'No summary.md found. Check debug bundle.'; }
            core.info(`summary.md length: ${body.length}`);

            // 2) Find existing open issue by title (no label filter)
            const allOpen = await github.paginate(
              github.rest.issues.listForRepo,
              { owner, repo, state: 'open', per_page: 100 }
            );
            let issue = allOpen.find(i => i.title === title);

            // 3) Best-effort ensure label exists (ignore errors if not allowed)
            let canUseLabel = false;
            try {
              await github.rest.issues.getLabel({ owner, repo, name: wantLabel });
              canUseLabel = true;
            } catch (e) {
              try {
                await github.rest.issues.createLabel({ owner, repo, name: wantLabel, color: '0e8a16' });
                canUseLabel = true;
              } catch (e2) {
                core.warning(`Could not ensure label '${wantLabel}': ${e2?.message || e2}`);
              }
            }

            // 4) Create or update the digest issue
            if (!issue) {
              const args = { owner, repo, title, body };
              if (canUseLabel) args.labels = [wantLabel];
              issue = (await github.rest.issues.create(args)).data;
              core.info(`Created issue #${issue.number}`);
            } else {
              await github.rest.issues.update({ owner, repo, issue_number: issue.number, body });
              core.info(`Updated issue #${issue.number}`);
              if (canUseLabel) {
                try {
                  await github.rest.issues.addLabels({ owner, repo, issue_number: issue.number, labels: [wantLabel] });
                } catch (e3) {
                  core.warning(`Could not add label to issue #${issue.number}: ${e3?.message || e3}`);
                }
              }
            }

            // 5) Optional: mention a user
            const mention = process.env.NOTIFY_USER ? ` cc @${process.env.NOTIFY_USER}` : '';
            if (mention) {
              try {
                await github.rest.issues.createComment({
                  owner, repo, issue_number: issue.number, body: `Daily digest posted.${mention}`
                });
              } catch (e4) {
                core.warning(`Could not add mention comment: ${e4?.message || e4}`);
              }
            }

      - name: Upload debug bundle
        uses: actions/upload-artifact@v4
        with:
          name: debug-data
          path: debug-data.zip
          if-no-files-found: warn

      - name: Upload repo snapshot
        uses: actions/upload-artifact@v4
        with:
          name: repo-snapshot
          path: repo-snapshot.zip
          if-no-files-found: warn

      - name: Upload latest outputs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: latest-run
          if-no-files-found: ignore
          path: |
            data/out/latest/runner.log
            data/out/latest/assistant_feed.json
            data/out/latest/items.discovered.json
            data/out/latest/items.enriched.json
            data/out/latest/summary.md
            data/out/latest/diag.json
            data/out/latest/exports/selection_breakdown.json
            data/out/latest/exports/user_model.json

      # Save caches so next run restores an ever-growing pool
      - name: Save pool/tmdb caches
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            data/cache/pool
            data/cache/tmdb
          key: pool-${{ runner.os }}-${{ env.REGION }}-${{ env.POOL_CACHE_VERSION }}-${{ github.run_id }}