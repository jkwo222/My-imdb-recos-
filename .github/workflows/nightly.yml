# File: .github/workflows/nightly.yml
# WHY: Single nightly workflow; assumes data/ratings.csv is in repo; normalizes outputs and posts accurate issue content.

name: Nightly Recos

on:
  workflow_dispatch:
  schedule:
    - cron: "45 3 * * *"  # 03:45 UTC nightly

concurrency:
  group: nightly-recos-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write
  issues: write

env:
  PYTHONUNBUFFERED: "1"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  DATA_DIR: data
  CACHE_DIR: data/cache
  OUTPUT_DIR: data/out/latest
  TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
  OMDB_API_KEY: ${{ secrets.OMDB_API_KEY }}
  IMDB_USER_ID: ${{ vars.IMDB_USER_ID || secrets.IMDB_USER_ID }}
  REGION: US
  ORIGINAL_LANGS: en
  SUBS_INCLUDE: netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus
  TMDB_PAGES_MOVIE: "12"   # WHY: matches your latest successful run
  TMDB_PAGES_TV: "12"
  MAX_CATALOG: "6000"
  INCLUDE_TV_SEASONS: "true"
  SKIP_WINDOW_DAYS: "4"

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Verify IMDb export exists
        # WHY: You chose to keep ratings.csv in the repo; fail fast if missing.
        run: |
          if [ ! -s "data/ratings.csv" ]; then
            echo "::error file=data/ratings.csv::Missing or empty data/ratings.csv (export from IMDb)."
            exit 1
          fi

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Prepare dirs
        # WHY: Ensure all output dirs exist even if repo is clean.
        run: |
          mkdir -p "$CACHE_DIR" "$OUTPUT_DIR" "data/debug" "data/out"

      - name: Run engine (nightly)
        env:
          IMDB_RATINGS_CSV_PATH: data/ratings.csv
        run: |
          set -e
          python -m engine.runner 2>&1 | tee data/debug/runner.log

      - name: Normalize outputs (discover latest assistant_feed.json)
        # WHY: Engine writes to dated subfolder (e.g., data/out/daily/2025-08-16); copy newest feed to data/out/latest.
        run: |
          set -euo pipefail
          mkdir -p data/out/latest
          FEED_PATH="$(find data/out -type f -name 'assistant_feed.json' -printf '%T@ %p\n' \
            | sort -nr | head -n1 | awk '{ $1=""; sub(/^ /,""); print }')"
          if [ -z "${FEED_PATH:-}" ]; then
            echo "::warning::assistant_feed.json not found under data/out/**"
            exit 0
          fi
          echo "Found feed at: $FEED_PATH"
          cp -f "$FEED_PATH" data/out/latest/assistant_feed.json
          PARENT_DIR="$(dirname "$FEED_PATH")"
          echo "ARTIFACT_DIR=$PARENT_DIR" >> $GITHUB_ENV

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-recos-${{ github.run_number }}
          path: |
            data/debug/runner.log
            data/out/latest/assistant_feed.json
            ${{ env.ARTIFACT_DIR }}/**
          if-no-files-found: warn

      - name: Create/Update "Nightly picks" issue (from JSON telemetry)
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const core = require('@actions/core');
            const path = 'data/out/latest/assistant_feed.json';
            if (!fs.existsSync(path)) {
              core.warning('assistant_feed.json not found; skipping issue creation.');
              return;
            }
            const payload = JSON.parse(fs.readFileSync(path, 'utf8'));
            const items = Array.isArray(payload.items) ? payload.items : (payload.top || []);
            const tel = payload.telemetry || {};
            const pagePlan = tel.page_plan || {};
            const providers = process.env.SUBS_INCLUDE ? process.env.SUBS_INCLUDE.split(',').join(', ') : 'n/a';

            // Derive counts robustly to avoid stale header metrics
            const pool = tel.pool ?? tel.pool_size ?? (tel.pool_counts ? (tel.pool_counts.movie||0)+(tel.pool_counts.tv||0) : undefined);
            const shortlist = tel.shortlist ?? items.length;
            const shown = items.length;

            const lines = [];
            lines.push('### Top 10');
            items.slice(0, 10).forEach((it, i) => {
              const name = it.title || it.name || 'Untitled';
              const year = it.year || (it.release_date ? String(it.release_date).slice(0,4) : '');
              lines.push(`${i+1}. ${name}${year ? ' ('+year+')' : ''}`);
            });
            lines.push('');
            lines.push(`**Counts:** pool=${pool ?? 'n/a'}, shortlist=${shortlist}, shown=${shown}`);
            lines.push(`**Page plan:** movie_pages=${pagePlan.movie_pages ?? 'n/a'} tv_pages=${pagePlan.tv_pages ?? 'n/a'} rotate_minutes=${pagePlan.rotate_minutes ?? 'n/a'} slot=${pagePlan.slot ?? 'n/a'}`);
            lines.push(`**Providers:** ${providers}`);
            lines.push('');
            lines.push('This product uses the TMDB and OMDb APIs but is not endorsed or certified by them.');
            lines.push('');
            lines.push('#### assistant_feed.json');
            lines.push('```json');
            lines.push(JSON.stringify(payload, null, 2));
            lines.push('```');

            const body = lines.join('\n');
            const title = `Nightly picks â€” #${process.env.GITHUB_RUN_NUMBER}`;

            // Rolling Nightly issue
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'nightly-picks'
            });

            if (issues.length) {
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issues[0].number,
                title,
                body
              });
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title,
                body,
                labels: ['nightly-picks']
              });
            }

# File: .gitignore
# WHY: Keep repo clean; track ratings.csv but ignore generated outputs & caches.
# Python
__pycache__/
*.pyc
*.pyo
*.pyd
*.egg-info/
.build/
.venv/
venv/

# Engine outputs & caches
data/out/
data/cache/
data/debug/

# Keep ratings.csv tracked even if you ignore data/*
# (If you already ignore 'data/*', add the two lines below after that rule)
#!data/
#!data/ratings.csv