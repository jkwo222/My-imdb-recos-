name: nightly

on:
  schedule:
    - cron: "17 9 * * *"
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        attempt: [1, 2, 3, 4, 5, 6, 7]
    env:
      PYTHONUTF8: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      REGION: US
      ORIGINAL_LANGS: '["en"]'
      # Expand # of TMDB pages searched each run
      DISCOVER_PAGES: "12"
      SUBS_INCLUDE: "netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus"
      IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
      TMDB_ACCESS_TOKEN: ${{ secrets.TMDB_ACCESS_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: "pip-${{ runner.os }}-py311-${{ hashFiles('**/requirements*.txt') }}"
          restore-keys: |
            pip-${{ runner.os }}-py311-

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Run pipeline (attempt ${{ matrix.attempt }})
        id: run
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p data/out data/cache
          python -m engine.runner
          echo "RUN_DONE=1" >> "$GITHUB_OUTPUT"

      - name: Prepare 'latest' folder
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if compgen -G "data/out/run_*" > /dev/null; then
            latest_dir="$(ls -dt data/out/run_* | head -n1)"
            rm -rf data/out/latest
            mkdir -p data/out
            cp -r "$latest_dir" "data/out/latest"
            echo "Latest run directory: $latest_dir"
            ls -al "data/out/latest" || true
          else
            echo "No run_* directories found under data/out"
          fi

      - name: Build compact debug artifact
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          rm -f debug-data.zip
          mkdir -p debug-bundle
          if [ -d "data/out/latest" ]; then
            cp -f data/out/latest/runner.log debug-bundle/ 2>/dev/null || true
            cp -f data/out/latest/assistant_feed.json debug-bundle/ 2>/dev/null || true
            cp -f data/out/latest/items.discovered.json debug-bundle/ 2>/dev/null || true
            cp -f data/out/latest/items.enriched.json debug-bundle/ 2>/dev/null || true
            cp -f data/out/latest/summary.md debug-bundle/ 2>/dev/null || true
          fi
          {
            echo "REGION=${REGION}"
            echo "SUBS_INCLUDE=${SUBS_INCLUDE}"
            echo "ORIGINAL_LANGS=${ORIGINAL_LANGS}"
            echo "DISCOVER_PAGES=${DISCOVER_PAGES}"
          } > debug-bundle/env.txt
          (cd debug-bundle && zip -q -r ../debug-data.zip .) || true
          ls -lh debug-data.zip || true

      - name: Upload debug artifact (small)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-data-attempt-${{ matrix.attempt }}
          path: debug-data.zip
          if-no-files-found: warn
          retention-days: 14

      - name: Upload latest results (human-readable)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: site-out-attempt-${{ matrix.attempt }}
          path: data/out/latest
          if-no-files-found: warn
          retention-days: 7

      - name: Cleanup old run folders
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if compgen -G "data/out/run_*" > /dev/null; then
            ls -dt data/out/run_* | tail -n +6 | xargs -r rm -rf --
          fi