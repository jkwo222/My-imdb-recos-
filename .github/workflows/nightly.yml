name: nightly

on:
  workflow_dispatch:
  schedule:
    - cron: "30 16 * * *"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-24.04

    env:
      PYTHONUTF8: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      REGION: US
      ORIGINAL_LANGS: '["en"]'
      DISCOVER_PAGES: "12"
      SUBS_INCLUDE: netflix,prime_video,hulu,max,disney_plus,apple_tv_plus,peacock,paramount_plus
      # Tell the engine where your ratings live (your repo layout)
      RATINGS_CSV_PATH: data/user/ratings.csv
      IMDB_USER_ID: ${{ secrets.IMDB_USER_ID }}
      TMDB_ACCESS_TOKEN: ${{ secrets.TMDB_ACCESS_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-py311-${{ hashFiles('requirements.txt', 'requirements-dev.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-py311-

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Run engine
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p data/out data/cache
          echo "PYTHON_VERSION=$(python -V 2>&1)" >> "$GITHUB_ENV"
          python -m engine.runner
          echo "RUN_DONE=1" >> "$GITHUB_OUTPUT"

      # Make sure we have a last_run_dir marker and a *copy* in data/out/latest
      - name: Stamp last run marker (fallback)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/out
          if [ ! -f data/out/last_run_dir.txt ]; then
            if compgen -G "data/out/run_*" > /dev/null; then
              latest_dir="$(ls -dt data/out/run_* | head -n1)"
              printf '%s\n' "$latest_dir" > data/out/last_run_dir.txt
              echo "Stamped last_run_dir.txt with: $latest_dir"
            else
              echo "WARNING: no run_* dirs found; nothing to stamp"
            fi
          fi

      - name: Prepare latest dir for upload (copy, not symlink)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/out
          if [ -f data/out/last_run_dir.txt ]; then
            latest_dir="$(cat data/out/last_run_dir.txt)"
          elif compgen -G "data/out/run_*" > /dev/null; then
            latest_dir="$(ls -dt data/out/run_* | head -n1)"
          else
            echo "No run_* directories found under data/out"
            exit 0
          fi
          rm -rf data/out/latest
          # Copy to avoid symlink upload issues
          cp -r "$latest_dir" "data/out/latest"
          echo "Latest run directory (copied): $latest_dir"
          ls -al "data/out/latest" || true

      - name: Upload site artifact
        uses: actions/upload-artifact@v4
        with:
          name: site-out
          path: data/out/latest
          if-no-files-found: warn
          retention-days: 7

      - name: Bundle debug data (as directory, not zip)
        shell: bash
        run: |
          set -euo pipefail
          rm -rf debug-data
          mkdir -p debug-data

          # 1) Copy primary outputs if present
          if [ -d "data/out/latest" ]; then
            cp -f data/out/latest/runner.log            debug-data/ 2>/dev/null || true
            cp -f data/out/latest/assistant_feed.json   debug-data/ 2>/dev/null || true
            cp -f data/out/latest/items.discovered.json debug-data/ 2>/dev/null || true
            cp -f data/out/latest/items.enriched.json   debug-data/ 2>/dev/null || true
            cp -f data/out/latest/summary.md            debug-data/ 2>/dev/null || true
            cp -f data/out/latest/diag.json             debug-data/ 2>/dev/null || true
            # Tail of runner.log for quick view
            if [ -f data/out/latest/runner.log ]; then
              tail -n 200 data/out/latest/runner.log > debug-data/runner-tail.txt || true
            fi
          fi

          # 2) Minimal env snapshot
          {
            echo "REGION=${REGION}"
            echo "SUBS_INCLUDE=${SUBS_INCLUDE}"
            echo "ORIGINAL_LANGS=${ORIGINAL_LANGS}"
            echo "DISCOVER_PAGES=${DISCOVER_PAGES}"
            echo "RATINGS_CSV_PATH=${RATINGS_CSV_PATH}"
          } > debug-data/env.txt

          # 3) Sanitized full env
          {
            printenv | sort | sed \
              -e 's/\(AUTH\|TOKEN\|SECRET\|PASSWORD\|KEY\)=.*/\1=***REDACTED***/I' \
              -e 's/\(COOKIE\)=.*/\1=***REDACTED***/I'
            if [ -n "${TMDB_ACCESS_TOKEN:-}" ]; then
              echo "HINT_TMDB_ACCESS_TOKEN_LEN=${#TMDB_ACCESS_TOKEN}"
            else
              echo "HINT_TMDB_ACCESS_TOKEN_LEN=0"
            fi
            if [ -n "${IMDB_USER_ID:-}" ]; then
              echo "HINT_IMDB_USER_ID_SET=1"
            else
              echo "HINT_IMDB_USER_ID_SET=0"
            fi
          } > debug-data/env-sanitized.txt

          # 4) Repo tree + detailed listing
          {
            echo "# REPO TREE (find .)"
            find . -mindepth 1 -maxdepth 6 -printf "%y %M %u %g %9s %TY-%Tm-%Td %TT %p\n" 2>/dev/null | sort || true
            echo
            echo "# DETAILED LISTING (ls -lR)"
            ls -alR || true
          } > debug-data/tree.txt

          # 5) Symlink targets (should be copies now, but record anyway)
          {
            echo "# SYMLINK TARGETS"
            if [ -L data/out/latest ]; then
              echo "data/out/latest is a symlink to -> $(readlink -f data/out/latest 2>/dev/null || echo '<unresolvable>')"
            else
              echo "data/out/latest is a directory (copied)"
            fi
            if [ -f data/out/last_run_dir.txt ]; then
              echo "last_run_dir: $(cat data/out/last_run_dir.txt)"
            else
              echo "last_run_dir: <missing>"
            fi
          } > debug-data/links.txt

          # 6) Git context
          {
            echo "# git rev"
            git log -1 --oneline || true
            echo
            echo "# git status"
            git status --porcelain=v1 || true
            echo
            echo "# git remotes"
            git remote -v || true
          } > debug-data/git.txt

          # 7) Python environment
          {
            echo "# Python info"
            which python || true
            python --version || true
            echo
            echo "# pip freeze"
            pip freeze || true
          } > debug-data/python.txt

          # 8) Directory sizes & free space
          {
            echo "# sizes"
            du -sh . 2>/dev/null || true
            du -sh data/out 2>/dev/null || true
            du -sh data/cache 2>/dev/null || true
            echo
            echo "# df (filesystem free space)"
            df -h . || true
          } > debug-data/dirs.txt

          # 9) Focus listings
          {
            echo "# data/out (top)"
            ls -al data/out 2>/dev/null || true
            echo
            echo "# data/out/latest (top)"
            ls -al data/out/latest 2>/dev/null || true
            echo
            echo "# data/cache (top)"
            ls -al data/cache 2>/dev/null || true
            echo
            echo "# data/cache/tmdb (top)"
            ls -al data/cache/tmdb 2>/dev/null || true
          } > debug-data/listings.txt

      - name: Upload debug artifact
        uses: actions/upload-artifact@v4
        with:
          name: debug-data
          path: debug-data
          if-no-files-found: warn
          retention-days: 14